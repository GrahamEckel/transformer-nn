{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import BertTokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "#print('Loading BERT tokenizer...')\n",
    "#tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create the author_abstracts df\n",
    "\n",
    "with open(\"AuthAbs_full.json\", 'r', encoding='utf-8') as test:\n",
    "    test = json.load(test)\n",
    "    Author_df = pd.DataFrame.from_dict(test[0], orient='index')\n",
    "\n",
    "Author_df.fillna('', inplace=True)\n",
    "Author_df['Corpus'] = Author_df.astype(str).values.sum(axis=1)\n",
    "Author_df = Author_df.filter([\"Corpus\"]).reset_index().rename(columns={\"index\": \"AuthorID\"})\n",
    "Author_df['Corpus'].replace('', np.nan, inplace=True)\n",
    "Author_df.dropna(subset=['Corpus'], inplace=True)\n",
    "#Authordf['Corpus'].str.replace('\\d+', '')  ## remove all numbers?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Author_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create the papers df\n",
    "\n",
    "paper_abstracts = []\n",
    "with open(\"E:\\Data\\Kaggle-Covid\\papers\\papers2.json\", 'r', encoding='utf-8') as papers:\n",
    "    papers = json.load(papers)\n",
    "    for j in tqdm(papers):\n",
    "        if j:\n",
    "            try:        \n",
    "                paper_abstracts.append(j[\"abstract\"])\n",
    "                #paper_abstracts.append(j[\"abstract\"])  ## convert this to a dict \n",
    "            except:   \n",
    "                #print the error message from sys\n",
    "                print(\"error:\", sys.exc_info()[0])\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "Paper_df = pd.DataFrame(paper_abstracts, columns=[\"Paper_Abstracts\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Paper_df['Paper_Abstracts'].replace('', np.nan, inplace=True)\n",
    "Paper_df.dropna(subset=['Paper_Abstracts'], inplace=True)\n",
    "Paper_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT input (replace all this and below with pytorch)\n",
    "author_abstract = Author_df.Corpus.values\n",
    "author_labels = Author_df.AuthorID.values\n",
    "paper_abstract = Paper_df.Paper_Abstracts.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gram_range = (1, 1)\n",
    "stop_words = \"english\"\n",
    "top_n_words = 10\n",
    "np.random.seed(2021-12-30)\n",
    "model = SentenceTransformer('distilbert-base-nli-mean-tokens')\n",
    "\n",
    "auth2paper_final = []\n",
    "for i in tqdm(range(0, 100)): \n",
    "#for i in tqdm(range(0, len(author_abstract))): \n",
    "    count = CountVectorizer(ngram_range=n_gram_range, stop_words=stop_words).fit([author_abstract[i]])\n",
    "    candidates = count.get_feature_names()\n",
    "    candidate_embeddings = model.encode(candidates)\n",
    "    \n",
    "    auth2paper_cosim = []\n",
    "    \n",
    "    for k in range(0, 1000): \n",
    "    #for k in range(0, len(paper_abstract)):   \n",
    "        doc_embedding = model.encode([paper_abstract[k]])\n",
    "        cosine_sim = cosine_similarity(doc_embedding, candidate_embeddings)\n",
    "        #top_n_keywords = [candidates[index] for index in cosine_sim.argsort()[0][-top_n_words:]]\n",
    "        top_n_candidate_embeddings = np.reshape(np.mean(np.array([candidate_embeddings[index] for index in cosine_sim.argsort()[0][-top_n_words:]]), axis=0), (1, -1))\n",
    "        #top_n_candidate_embeddings = np.reshape(arr_list, (1, -1))\n",
    "        cosine_sim_top_n = cosine_similarity(doc_embedding, top_n_candidate_embeddings)\n",
    "        unravelled = float(np.ravel(cosine_sim_top_n))\n",
    "        auth2paper_cosim.append(unravelled)\n",
    "\n",
    "    auth2paper_final.append(auth2paper_cosim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_index = []\n",
    "paper_top_scores = []\n",
    "\n",
    "for i in tqdm(range(0,len(auth2paper_final))):\n",
    "    sample_list1 = [] \n",
    "    sample_list2 = [] \n",
    "    for index, value in sorted(enumerate(auth2paper_final[i]), reverse=True, key=lambda x: x[1])[:10]:\n",
    "        sample_list1.append(index)\n",
    "        sample_list2.append(value)\n",
    "    paper_index.append(sample_list1)\n",
    "    paper_top_scores.append(sample_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_au_id <- clean author IDs\n",
    "final_df = pd.DataFrame({'Author ID': Author_df['AuthorID'].head(100),\n",
    "                         'Top 10 Cosine Similarity Scores': paper_top_scores,\n",
    "                         'Paper Indices':paper_index\n",
    "                        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(\"final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "01dcfc14ced2cd3f3ca8b1eab5863829d3299fc9b429a7e61faa3aaa90451b9a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('NLP-startup': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
